---
Title: 正答率ほぼ100%だった数字カード識別が全国大会ではダメダメになった話【ETロボコン2019】
Category:
- ETロボコン
- ノウハウ
- プログラミング
- Python
Date: 2019-12-02T22:28:08+09:00
URL: https://korosuke613.hatenablog.com/entry/2019/12/02/222808
EditURL: https://blog.hatena.ne.jp/korosuke613/korosuke613.hatenablog.com/atom/entry/26006613475077632
---

<!-- ここに導入を書く -->
<figure class="figure-image figure-image-fotolife" title="タイトルサムね">[f:id:korosuke613:20191202222315p:plain]</figure>

こんにちは。僕は、ETロボコン2019のデベロッパー部門アドバンスドクラスに出場したK-Labというチームの平木場です。

今年の大会には、ブロックビンゴというゲームがあり、「数字カード」というアナログ数字が書かれたカードをカメラで読み取り((カメラで読まずに走行体で走査するのもありですが、カメラを使った方がメリットがあると判断し、カメラを使いました。))、数字を当てる必要がありました。

今回は、**開発環境（研究室に敷いたコース）、地区大会ではほぼ100%正答できたのに、全国大会ではまったく正答できなくなった話**をします。

個人的には来年もカメラシステムは存在すると考えてますので、反面教師にしていただければと思います。

**[ETロボコン&EV3 Advent Calendar 2019](https://qiita.com/advent-calendar/2019/etrobo-ev3rt) 3日目の記事です。**

<!-- 続きを読むのやつ -->
<!-- more -->

---

**目次**

[:contents]

<!-- ここに広告が入る -->
---

# TL;DR(要約)
- 数字認識を4層ニューラルネットワークを構築して識別した。**とてもうまく識別できていた**。
- 数字カードを入れているクリアファイルに**光りが反射することがあった**。
- まさか全国大会では**光の反射なんてないだろうと思っていた**。
- 全国大会会場でがっつり**光の反射があり、数字カードの識別はぜんぜんうまくいかなかった**。
- **光の反射対策をしていたチームは問題なくゲーム攻略できていた**。

# K-Labの数字識別方法
僕たちは、数字の識別のために、4層ニューラルネットワークの分類器を用意し、自前で作成したデータセットを学習させました。

## 分類器

<figure class="figure-image figure-image-fotolife" title="4層ニューラルネットワーク">[f:id:korosuke613:20191202184943p:plain]</figure>

PythonでChainer利用しました。
```python
import chainer.links as L
import chainer.functions as F
import chainer


# Network definition
class MLP(chainer.Chain):

    def __init__(self, n_units, n_out):
        super(MLP, self).__init__()
        with self.init_scope():
            # the size of the inputs to each layer will be inferred
            self.l1 = L.Linear(None, n_units)  # n_in -> n_units
            self.l2 = L.Linear(None, n_units)  # n_units -> n_units
            self.l3 = L.Linear(None, n_out)  # n_units -> n_out

    def forward(self, x):
        h1 = F.relu(self.l1(x))
        h2 = F.relu(self.l2(h1))
        return self.l3(h2)
```

これ実は、[ChainerのMNIST分類サンプル](https://github.com/chainer/chainer/blob/master/examples/mnist/train_mnist.py)のコードまんまです。

ただ、MNISTのデータセットは手書き数字のセットなので、ETロボコンの数字カード識別には利用できませんでした。
そこで、学習データを自前で用意しました。

## データセット生成
あらかじめ撮影しておいた数字カード画像に前処理を施し、1つの数字につき1000枚の画像を自動生成しました。
前処理の際に、明るさ変更、拡大縮小、回転をランダムに行うことで、データを水増ししました。
<figure class="figure-image figure-image-fotolife" title="データセット生成の流れ">[f:id:korosuke613:20191202195221p:plain]</figure>

<div onclick="obj=document.getElementById('20190720_folding_text').style; obj.display=(obj.display=='none')?'block':'none';">
<a style="cursor:pointer;">▶拡大縮小回転を行うコードがこちらです。
</a>
</div>
<div id="20190720_folding_text" style="display:none;clear:both;">
```python
def change_angle(image):  # 今気づいたけどchange_angleって名前がよくない
    # 中心位置取得
    center = tuple(np.array([image.shape[1] * 0.5, image.shape[0] * 0.5]))

    # 回転させたい角度°(ラジアンではない)
    rand_num = np.random.rand() * 60.0 - 30.0
    angle = rand_num

    # 拡大比率
    rand_num = np.random.rand() * 0.5 - 0.25
    scale = 1.0 + rand_num

    # 回転変換行列の算出![edges.png](https://qiita-image-store.s3.amazonaws.com/0/294506/5d919d71-d994-ab16-28d2-c0217b975ff0.png)

    affine_mat = cv2.getRotationMatrix2D(center, angle, scale)

    # 平均色の取得
    mean = get_mean_color(image)
    # アフィン変換(回転)
    height, width = image.shape[:2]
    rotation_image = cv2.warpAffine(image, affine_mat, (width, height), flags=cv2.INTER_CUBIC,
                                    borderValue=(mean["b"], mean["g"], mean["r"]))

    return rotation_image
```
</div>

[コード全体はこちら](https://github.com/KatLab-MiyazakiUniv/CameraSystem/blob/master/source/detection_number/training_scripts/create_data.py)

これらの処理を行うことで、カメラの角度や部屋の明るさが少しくらい変わっても柔軟に対応できるようになりました。

# 研究室ではほぼ100%正答できていた

上記の前処理を行って作ったデータセットを分類器で学習し、研究室に用意したコースで動作確認、実験をしたところ、ほぼ100%動作していました。 

しかし、蛍光灯の明かりが数字カードを入れているクリアファイルに大きく反射した場合、失敗していました。

僕たちは、**蛍光灯の明かりが反射してしまうのは選んだクリアファイルが良くなかったからで、大会の環境では光の反射は存在しない**と思い込んでしまっていました。

だから、**光の反射は無いものとして扱ってしまいました**。

# 全国大会会場でまったく正答できない
地区大会でも数字カードはいつも正しく正答できていたので、全国大会まで一切コードをいじることはありませんでした。

しかし、全国大会の試走時にさっぱり識別できなくなりました。

全国大会会場では、数字カードのクリアファイルに**光ががっつり反射し、数字の一部が欠損**していました。

**全国大会の会場では光が反射するわけはないと考えていたのはとんでもない思い込みでした。**

実際、**光の反射対策をしているチーム**は（モデルを見る限り）いくつかあって、そういったチームはブロックビンゴで**ボーナスサークル設置を達成していました**((あるチームは用意しておいた数字カードの画像から取得した光の反射の形を取り除き、それを取得した数字カードの画像とパターンマッチングする？という感じの方法でやっていました。))...

# 反省と教訓
僕たちは、数字カードに光が反射するわけがないと**思い込み**、光の反射対策をまったく行っていませんでした。

でも結局、運営側はわざわざそんな**親切なことはしてくれない**わけです。たぶん「**参加チームが未知の環境にどれだけ対応できるのか**」という部分も試しているんじゃないかなと思います。

今回の**反省**は、光が反射するわけないと**思い込んでしまっていたこと**です。

得られた**教訓**は、**思い込み（楽観視）は良くない**。**本番環境をもっと考察して、要求定義はするべき**だということです。

# おわりに
組込み系においては、本番環境とテスト環境の差を縮めることはとても大変だと思います。毎年ETロボコンに参加して、毎年テスト環境でうまくいってたのに本番環境でこけます。

環境の差を縮めるのは限界があるので、それよりも、あらゆる環境に適用できるようなソフトウェアを作るほうが近道かもしれません。

僕は来年に就職するので、ロボコンからは身を引きますが、この記事が、後輩やこれからロボコンに参加する人への反面教師になればいいなと思います。

[https://github.com/KatLab-MiyazakiUniv/CameraSystem:embed:cite]




<!-- 記事終わり線 -->
---

<!-- ここに脚注が来る -->
